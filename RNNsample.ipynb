{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55f3ec3-34ce-4747-aa01-49ef0560ddd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd            #读取数据\n",
    "import torch\n",
    "from torch import nn\t\t   #继承nn.Module构建rnn网络\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader #构建迭代器\n",
    "import matplotlib.pyplot as plt\t\t\t#绘图\n",
    "import h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc757d4-1c93-482e-8fae-f9f90b41f7f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train_power_forecast_history = pd.read_csv('./训练集/power_forecast_history.csv')\n",
    "train_power = pd.read_csv('./训练集/power.csv')\n",
    "train_stub_info = pd.read_csv('./训练集/stub_info.csv')\n",
    "\n",
    "test_power_forecast_history = pd.read_csv('./测试集/power_forecast_history.csv')\n",
    "test_stub_info = pd.read_csv('./测试集/stub_info.csv')\n",
    "# 聚合数据\n",
    "train_df = train_power_forecast_history.groupby(['id_encode','ds']).head(1)\n",
    "del train_df['hour']\n",
    "\n",
    "test_df = test_power_forecast_history.groupby(['id_encode','ds']).head(1)\n",
    "del test_df['hour']\n",
    "\n",
    "tmp_df = train_power.groupby(['id_encode','ds'])['power'].sum()\n",
    "tmp_df.columns = ['id_encode','ds','power']\n",
    "\n",
    "# 合并充电量数据\n",
    "train_df = train_df.merge(tmp_df, on=['id_encode','ds'], how='left')\n",
    "\n",
    "### 合并数据\n",
    "train_df = train_df.merge(train_stub_info, on='id_encode', how='left')\n",
    "test_df = test_df.merge(test_stub_info, on='id_encode', how='left')\n",
    "train_df['flag'] = train_df['flag'].map({'A':0,'B':1})\n",
    "test_df['flag'] = test_df['flag'].map({'A':0,'B':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f59c3177-8603-444e-97be-8edd1312915e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['latitude'] = train_df['h3'].apply(lambda x: h3.h3_to_geo(x)[0])\n",
    "train_df['longitude'] = train_df['h3'].apply(lambda x: h3.h3_to_geo(x)[1])\n",
    "test_df['latitude'] = test_df['h3'].apply(lambda x: h3.h3_to_geo(x)[0])\n",
    "test_df['longitude'] = test_df['h3'].apply(lambda x: h3.h3_to_geo(x)[1])\n",
    "train_df=train_df.drop('h3', axis=1)\n",
    "test_df=test_df.drop('h3', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade58c85-182e-4c4a-ab48-f3748ca2239d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_encode</th>\n",
       "      <th>ele_price</th>\n",
       "      <th>ser_price</th>\n",
       "      <th>after_ser_price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>ds</th>\n",
       "      <th>power</th>\n",
       "      <th>parking_free</th>\n",
       "      <th>flag</th>\n",
       "      <th>ac_equipment_kw</th>\n",
       "      <th>dc_equipment_kw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220415</td>\n",
       "      <td>2288.2240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>31.523294</td>\n",
       "      <td>120.096637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220416</td>\n",
       "      <td>2398.5730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>31.523294</td>\n",
       "      <td>120.096637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417</td>\n",
       "      <td>2313.0330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>31.523294</td>\n",
       "      <td>120.096637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220418</td>\n",
       "      <td>2095.3259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>31.523294</td>\n",
       "      <td>120.096637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220419</td>\n",
       "      <td>1834.3590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>31.523294</td>\n",
       "      <td>120.096637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_encode  ele_price  ser_price  after_ser_price  total_price   f1   f2  \\\n",
       "0          0       0.64       0.95             0.31         1.59  0.0  0.0   \n",
       "1          0       0.64       0.95             0.31         1.59  0.0  0.0   \n",
       "2          0       0.64       0.95             0.31         1.59  0.0  0.0   \n",
       "3          0       0.64       0.95             0.31         1.59  0.0  0.0   \n",
       "4          0       0.64       0.95             0.31         1.59  0.0  0.0   \n",
       "\n",
       "    f3        ds      power  parking_free  flag  ac_equipment_kw  \\\n",
       "0  1.0  20220415  2288.2240           1.0     0              0.0   \n",
       "1  1.0  20220416  2398.5730           1.0     0              0.0   \n",
       "2  1.0  20220417  2313.0330           1.0     0              0.0   \n",
       "3  1.0  20220418  2095.3259           1.0     0              0.0   \n",
       "4  1.0  20220419  1834.3590           1.0     0              0.0   \n",
       "\n",
       "   dc_equipment_kw   latitude   longitude  \n",
       "0           1440.0  31.523294  120.096637  \n",
       "1           1440.0  31.523294  120.096637  \n",
       "2           1440.0  31.523294  120.096637  \n",
       "3           1440.0  31.523294  120.096637  \n",
       "4           1440.0  31.523294  120.096637  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92c8797-4276-43c0-8e8c-d5b29b937041",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_encode</th>\n",
       "      <th>ele_price</th>\n",
       "      <th>ser_price</th>\n",
       "      <th>after_ser_price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>ds</th>\n",
       "      <th>parking_free</th>\n",
       "      <th>flag</th>\n",
       "      <th>ac_equipment_kw</th>\n",
       "      <th>dc_equipment_kw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2</td>\n",
       "      <td>178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20230415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>31.523294</td>\n",
       "      <td>120.096637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2</td>\n",
       "      <td>178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20230416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>31.523294</td>\n",
       "      <td>120.096637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2</td>\n",
       "      <td>178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20230417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>31.523294</td>\n",
       "      <td>120.096637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2</td>\n",
       "      <td>178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20230418</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>31.523294</td>\n",
       "      <td>120.096637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2</td>\n",
       "      <td>178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20230419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>31.523294</td>\n",
       "      <td>120.096637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_encode  ele_price  ser_price  after_ser_price  total_price  f1     f2  \\\n",
       "0          0     0.6414     0.3086           0.3086         0.95   2  178.0   \n",
       "1          0     0.6414     0.3086           0.3086         0.95   2  178.0   \n",
       "2          0     0.6414     0.3086           0.3086         0.95   2  178.0   \n",
       "3          0     0.6414     0.3086           0.3086         0.95   2  178.0   \n",
       "4          0     0.6414     0.3086           0.3086         0.95   2  178.0   \n",
       "\n",
       "   f3        ds  parking_free  flag  ac_equipment_kw  dc_equipment_kw  \\\n",
       "0 NaN  20230415           1.0     0              0.0           1440.0   \n",
       "1 NaN  20230416           1.0     0              0.0           1440.0   \n",
       "2 NaN  20230417           1.0     0              0.0           1440.0   \n",
       "3 NaN  20230418           1.0     0              0.0           1440.0   \n",
       "4 NaN  20230419           1.0     0              0.0           1440.0   \n",
       "\n",
       "    latitude   longitude  \n",
       "0  31.523294  120.096637  \n",
       "1  31.523294  120.096637  \n",
       "2  31.523294  120.096637  \n",
       "3  31.523294  120.096637  \n",
       "4  31.523294  120.096637  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edb56596-e2ce-4b3d-86f8-a155258a3d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a95b95d-56a3-45fa-99c2-b35c12322879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 365, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the dataframe to tensor again\n",
    "data_tensor = torch.tensor(train_df.values)\n",
    "\n",
    "# Extract the id_encode column as a separate tensor\n",
    "id_encode_tensor = data_tensor[:, 0].int()\n",
    "\n",
    "# Create a dictionary to hold tensors for each id_encode\n",
    "tensor_dict = {}\n",
    "\n",
    "# Unique id_encodes\n",
    "unique_ids = torch.unique(id_encode_tensor).numpy()\n",
    "\n",
    "# Loop over unique id_encodes and create tensors\n",
    "for uid in unique_ids:\n",
    "    mask = (id_encode_tensor == uid)\n",
    "    tensor_dict[uid] = data_tensor[mask]\n",
    "\n",
    "# Now let's stack these tensors to create a 3D tensor\n",
    "# First, we need to pad each tensor to have the same shape\n",
    "max_length = max([t.shape[0] for t in tensor_dict.values()])\n",
    "padded_tensors = []\n",
    "\n",
    "for t in tensor_dict.values():\n",
    "    # Pad tensor\n",
    "    pad_len = max_length - t.shape[0]\n",
    "    padded_tensor = nn.functional.pad(t, pad=(0, 0, 0, pad_len))\n",
    "    padded_tensors.append(padded_tensor)\n",
    "\n",
    "# Stack tensors to create a 3D tensor\n",
    "final_tensor = torch.stack(padded_tensors)\n",
    "\n",
    "final_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe88600-81a3-4cad-8299-4564d6263474",
   "metadata": {},
   "source": [
    "看下0站点，第二天的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d478b36-be0c-4387-a319-f1395ceea41b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 6.4000e-01, 9.5000e-01, 3.1000e-01, 1.5900e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 2.0220e+07, 2.3986e+03, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.4400e+03, 3.1523e+01, 1.2010e+02], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tensor[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ccab6c1-3a94-46e6-8599-aecf5b8696bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "# check final_tensor \n",
    "has_nan = torch.any(torch.isnan(final_tensor))\n",
    "print(has_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbb57f8f-5de1-44aa-8472-5942612774e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([500, 365, 15]), torch.Size([500, 365]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the index of the 'power' column in the original dataframe\n",
    "power_index = train_df.columns.get_loc('power')\n",
    "\n",
    "# Split X and y based on the correct index\n",
    "X = torch.cat((final_tensor[:, :, :power_index], final_tensor[:, :, power_index+1:]), dim=2)\n",
    "y = final_tensor[:, :, power_index]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "944e1052-0a03-4e92-9874-95e65309ead7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([400, 365, 15]),\n",
       " torch.Size([400, 365]),\n",
       " torch.Size([100, 365, 15]),\n",
       " torch.Size([100, 365]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "num_stations = X.shape[0]\n",
    "num_train_stations = int(0.8 * num_stations)\n",
    "num_val_stations = num_stations - num_train_stations\n",
    "# Create a dataset with stations as the main data points\n",
    "station_dataset = TensorDataset(X, y)\n",
    "\n",
    "# Split the dataset by stations using random_split\n",
    "train_dataset, val_dataset = random_split(station_dataset, [num_train_stations, num_val_stations])\n",
    "\n",
    "# Extract X and y from the datasets\n",
    "X_train, y_train = train_dataset[:][0], train_dataset[:][1]\n",
    "X_val, y_val = val_dataset[:][0], val_dataset[:][1]\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e467120-2702-4af1-9775-3a4aaadf1241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 365, 15])\n",
      "torch.Size([32, 365])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "#check the shapes of batches\n",
    "for batch_x, batch_y in train_loader:\n",
    "    print(batch_x.shape)\n",
    "    print(batch_y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d8429cd-e890-497d-8887-53eabacca601",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (rnn): RNN(15, 256, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)  # Output a prediction for each day\n",
    "\n",
    "    def forward(self, x):\n",
    "        # RNN layers\n",
    "        out, _ = self.rnn(x)\n",
    "\n",
    "        # Output layer\n",
    "        out = self.fc(out)\n",
    "        out = out.squeeze(-1)  # Remove the last dimension to get shape as (batch_size, sequence_length)\n",
    "        return out\n",
    "\n",
    "# Create the flexible model\n",
    "model = RNNModel(input_dim=15, hidden_dim=256)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33efd42a-ffbc-4b17-a6f3-b53fbc790377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.sqrt(self.mse(y_pred, y_true))\n",
    "\n",
    "# Define the RMSE loss function\n",
    "criterion = RMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52f90c0d-e9dd-4783-a937-c71fdb6e27cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000 => Train loss: 38.6352, Validation loss: 49.4562\n",
      "Epoch 1000/1000 => Train loss: 39.7252, Validation loss: 49.5566\n"
     ]
    }
   ],
   "source": [
    "# Set number of epochs\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 1000\n",
    "\n",
    "# Training loop with the modified model\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    # Move model and data to GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Training pass\n",
    "    train_loss = 0.0\n",
    "    for batch_x, batch_y in DataLoader(train_dataset, batch_size=32, shuffle=True):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_x.float())\n",
    "        loss = criterion(predictions, batch_y.float())\n",
    "        #print(batch_x.shape,predictions.shape,batch_y.float().shape)\n",
    "        #break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss / len(train_dataset))\n",
    "    #break\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "    # Move model and data to GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Validation pass\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in DataLoader(val_dataset, batch_size=32):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            predictions = model(batch_x.float())\n",
    "            loss = criterion(predictions, batch_y.float())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_losses.append(val_loss / len(val_dataset))\n",
    "\n",
    "    # Print epoch results\n",
    "    if epoch % 500 == 499:\n",
    "      print(f\"Epoch {epoch+1}/{num_epochs} => \"\n",
    "          f\"Train loss: {train_loss / len(train_dataset):.4f}, \"\n",
    "          f\"Validation loss: {val_loss / len(val_dataset):.4f}\")\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs} => \"\n",
    "          #f\"Train loss: {train_loss / len(train_dataset):.4f}, \"\n",
    "          #f\"Validation loss: {val_loss / len(val_dataset):.4f}\")\n",
    "\n",
    "#train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcdadc80-69c9-46af-8172-26b64a2946a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3500, 15])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.tensor(test_df.values)\n",
    "test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76100a55-f113-49f6-8370-f18d600118a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 7, 15])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the id_encode column as a separate tensor\n",
    "id_encode_tensor = test_tensor[:, 0].int()\n",
    "\n",
    "# Create a dictionary to hold tensors for each id_encode\n",
    "tensor_dict = {}\n",
    "\n",
    "# Unique id_encodes\n",
    "unique_ids = torch.unique(id_encode_tensor).numpy()\n",
    "\n",
    "# Loop over unique id_encodes and create tensors\n",
    "for uid in unique_ids:\n",
    "    mask = (id_encode_tensor == uid)\n",
    "    tensor_dict[uid] = test_tensor[mask]\n",
    "\n",
    "# Now let's stack these tensors to create a 3D tensor\n",
    "# First, we need to pad each tensor to have the same shape\n",
    "max_length = max([t.shape[0] for t in tensor_dict.values()])\n",
    "padded_tensors = []\n",
    "\n",
    "for t in tensor_dict.values():\n",
    "    # Pad tensor\n",
    "    pad_len = max_length - t.shape[0]\n",
    "    padded_tensor = nn.functional.pad(t, pad=(0, 0, 0, pad_len))\n",
    "    padded_tensors.append(padded_tensor)\n",
    "\n",
    "# Stack tensors to create a 3D tensor\n",
    "test_tensor = torch.stack(padded_tensors)\n",
    "\n",
    "test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7d2f920-c165-4285-9cea-eb289524f328",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation mode\n",
    "model.eval()\n",
    "# Move model and data to GPU\n",
    "model = model.to(device)\n",
    "predictions = model(test_tensor.to(device).float())\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28963ea3-8842-4973-87ae-c7802f41701c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3014765363.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[28], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    test_df['power']=predictions..detach().to('cpu').numpy()\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "predictions=predictions.reshape(-1)\n",
    "test_df['power']=predictions..detach().to('cpu').numpy()\n",
    "test_df['power'] = test_df['power'].apply(lambda x: 0 if x<0 else x)\n",
    "test_df[['id_encode','ds','power']].to_csv('resultRNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a997e68-8609-4834-b521-6309cec8c73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
